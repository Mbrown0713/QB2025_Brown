---
title: '7\. Worksheet: Diversity Synthesis'
author: "Madison Brown; Z620: Quantitative Biodiversity, Indiana University"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
geometry: margin=2.54cm
---
  
## OVERVIEW

In this worksheet, you will conduct exercises that reinforce fundamental concepts of biodiversity.
First, you will construct a site-by-species matrix by sampling confectionery taxa from a source community.
Second, you will make a preference-profile matrix, reflecting each student's favorite confectionery taxa. 
With this primary data structure, you will then answer questions and generate figures using tools from previous weeks, along with wrangling techniques that we learned about in class. 

## Directions:
1. In the Markdown version of this document in your cloned repo, change "Student Name" on line 3 (above) to your name.
2. Complete as much of the worksheet as possible during class.
3. Refer to previous handouts to help with developing of questions and writing of code.
4. Answer questions in the worksheet.
Space for your answer is provided in this document and indicated by the ">" character.
If you need a second paragraph be sure to start the first line with ">".
You should notice that the answer is highlighted in green by RStudio (color may vary if you changed the editor theme).
5. Before you leave the classroom, **push** this file to your GitHub repo.
6. For the assignment portion of the worksheet, follow the directions at the bottom of this file. 
7. When you are done, **Knit** the text and code into a PDF file.
8. After Knitting, submit the completed exercise by creating a **pull request** via GitHub.
Your pull request should include this file `7.DiversitySynthesis_Worskheet.Rmd` and the PDF output of `Knitr` (`DiversitySynthesis_Worskheet.pdf`).

## QUANTITATIVE CONFECTIONOLOGY

We will construct a site-by-species matrix using confectionery taxa (i.e, jelly beans). 
The instructors have created a **source community** with known abundance (*N*) and richness (*S*).
Like a real biological community, the species abundances are unevenly distributed such that a few jelly bean types are common while most are rare. 
Each student will sample the source community and bin their jelly beans into operational taxonomic units (OTUs).

## SAMPLING PROTOCOL: SITE-BY-SPECIES MATRIX

1. From the well-mixed source community, each student should take one Dixie Cup full of individuals.

2. At your desk, sort the jelly beans into different types (i.e., OTUs), and quantify the abundance of each OTU.  

3. Working with other students, merge data into a site-by-species matrix with dimensions equal to the number of students (rows) and taxa (columns)

4. Create a worksheet (e.g., Google sheet) and share the site-by-species matrix with the class. 

```{r, echo = FALSE, fig.align = 'center', out.width = "80%", fig.cap = "\\textbf{Left}: taxonomic key, \\textbf{Top right}: rank abundance distribution, \\textbf{Bottom right}: source community"}
knitr::include_graphics("data/jelly.png")
```

## SAMPLING PROTOCOL: PREFERENCE-PROFILE MATRIX

1. With your individual sample only, each student should choose their top 5-10 preferred taxa based on flavor, color, sheen, etc.

2. Working with other students, merge data into preference-profile incidence matrix where 1 = preferred and 0 = non-preferred taxa.

3. Create a worksheet (e.g., Google sheet) and share the preference-profile matrix with the class. 

### 1) R SETUP

In the R code chunk below, please provide the code to: 
1) Clear your R environment,
2) Print your current working directory,
3) Set your working directory to your `Week5-Confection/` folder, and
4) Load the `vegan` R package (be sure to install first if you have not already).

```{r}
rm(list = ls())
getwd()
setwd("/cloud/project/QB2025_Brown/Week5-Confection")
library(vegan)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(broom)

```

## DATA ANALYSIS

**Question 1:** In the space below, generate a rarefaction plot for all samples of the source community. 
Based on these results, discuss how individual vs. collective sampling efforts capture the diversity of the source community.

```{r}

library(readr)
Jellybean_SbyS <- read_csv("/cloud/project/QB2025_Brown/Week5-Confection/Jelly belly data! - SbyS.csv")

s.obs <- function(x = ""){
  rowSums(x > 0) * 1
}

s.obs(Jellybean_SbyS)

Jellybean_obs <- s.obs(Jellybean_SbyS)

str(Jellybean_SbyS)

Jellybean_SbyS <- as.data.frame(lapply(Jellybean_SbyS, as.numeric))

Jellybean_SbyS[is.na(Jellybean_SbyS)] <- 0 

Min.N <- min(rowSums(Jellybean_SbyS))

s.rarefy <- rarefy(x = Jellybean_SbyS, sample = Min.N, se = TRUE)

rarecurve(x = Jellybean_SbyS, step = 20, col = "blue", cex = 0.6, las = 1)

abline(0, 1, col = 'red')
text(1500, 1500, "1:1", pos = 2, col = 'red')
```

> ***Answer 1***:
> Individual sampling efforts are not the most ideal because it is highly unlikely that you will be able to sample every species within an area and if that is your goal, it is very hard to do. Additionally, if you analyze everyone's samples individually, you are not able to determine large trends or data consistency. If you utilize community sampling efforts, you can determine patterns and organize and graph all of the collected data to better visualize it. Community sampling efforts can also be more ideal, but it is likely that someone will sample something that you or someone else may have missed. 


**Question 2:** Starting with the site-by-species matrix, visualize beta diversity.
In the code chunk below, conduct principal coordinates analyses (PCoA) using both an abundance- and incidence-based resemblance matrix.
Plot the sample scores in species space using different colors, symbols, or labels.
Which "species" are contributing the patterns in the ordinations?
How does the choice of resemblance matrix affect your interpretation?

```{r}
# Abundance Based 

bean.db <- vegdist(Jellybean_SbyS, method = "bray", upper = TRUE, diag = TRUE)

bean.pcoa <- cmdscale(bean.db, eig = TRUE, k = 3)

Explainvar1 <- round(bean.pcoa$eig[1] / sum(bean.pcoa$eig), 3) * 100
Explainvar2 <- round(bean.pcoa$eig[2] / sum(bean.pcoa$eig), 3) * 100
Explainvar3 <- round(bean.pcoa$eig[3] / sum(bean.pcoa$eig), 3) * 100
Sum.eig <- sum(Explainvar1, Explainvar2, Explainvar3)

head(row.names(bean.pcoa$points))

rownames(bean.pcoa$points) <- 1:nrow(bean.pcoa$points)

par(mar = c(5,5,1,2) + 0.1)

plot(bean.pcoa$points[,1], bean.pcoa$points[,2], 
     xlab = paste("PCoA 1 (", Explainvar1, "%)", sep = ""),
     ylab = paste("PCoA 2 (", Explainvar2, "%)", sep = ""),
     pch = 16, cex = 2.0, type = "n", cex.lab = 1.5,
     cex.axis = 1.2, axes = FALSE,
     xlim = range(bean.pcoa$points[,1]) * 1.1,  
     ylim = range(bean.pcoa$points[,2]) * 1.1)  


axis(side = 1, labels = T, lwd.ticks = 2, cex.axis = 1.2, las = 1)
axis(side = 2, labels = T, lwd.ticks = 2, cex.axis = 1.2, las = 1)
abline(h = 0, v = 0, lty = 3)
box(lwd = 2)

points(bean.pcoa$points[ ,1], bean.pcoa$points[ ,2],
       pch = 19, cex = 2.5, bg = "gray", col = "gray")
text(bean.pcoa$points[ ,1], bean.pcoa$points[ ,2], 
     labels = row.names(bean.pcoa$points), cex = 1.0, pos = NULL)

JellyREL <- Jellybean_SbyS
  for(i in 1:nrow(Jellybean_SbyS)){
    JellyREL[i, ] = Jellybean_SbyS[i, ] / sum(Jellybean_SbyS[i, ])
  }

library(vegan)

`add.spec.scores.class` <-
  function(ordi,comm,method="cor.scores",multi=1,Rscale=F,scaling="1") {
    ordiscores <- scores(ordi,display="sites")
    n <- ncol(comm)
    p <- ncol(ordiscores)
    specscores <- array(NA,dim=c(n,p))
    rownames(specscores) <- colnames(comm)
    colnames(specscores) <- colnames(ordiscores)
    if (method == "cor.scores") {
      for (i in 1:n) {
        for (j in 1:p) {specscores[i,j] <- cor(comm[,i],ordiscores[,j],method="pearson")}
      }
    }
    if (method == "wa.scores") {specscores <- wascores(ordiscores,comm)}
    if (method == "pcoa.scores") {
      rownames(ordiscores) <- rownames(comm)
      eigenv <- ordi$eig
      accounted <- sum(eigenv)
      tot <- 2*(accounted/ordi$GOF[2])-(accounted/ordi$GOF[1])
      eigen.var <- eigenv/(nrow(comm)-1)
      neg <- length(eigenv[eigenv<0])
      pos <- length(eigenv[eigenv>0])
      tot <- tot/(nrow(comm)-1)
      eigen.percen <- 100*eigen.var/tot
      eigen.cumpercen <- cumsum(eigen.percen)
      constant <- ((nrow(comm)-1)*tot)^0.25
      ordiscores <- ordiscores * (nrow(comm)-1)^-0.5 * tot^-0.5 * constant
      p1 <- min(p, pos)
      for (i in 1:n) {
        for (j in 1:p1) {
          specscores[i,j] <- cor(comm[,i],ordiscores[,j])*sd(comm[,i])/sd(ordiscores[,j])
          if(is.na(specscores[i,j])) {specscores[i,j]<-0}
        }
      }
      if (Rscale==T && scaling=="2") {
        percen <- eigen.var/tot
        percen <- percen^0.5
        ordiscores <- sweep(ordiscores,2,percen,"/")   
        specscores <- sweep(specscores,2,percen,"*")
      }
      if (Rscale==F) {
        specscores <- specscores / constant
        ordiscores <- ordi$points
      }        
      ordi$points <- ordiscores
      ordi$eig <- eigen.var
      ordi$eig.percen <- eigen.percen
      ordi$eig.cumpercen <- eigen.cumpercen
      ordi$eigen.total <- tot
      ordi$R.constant <- constant
      ordi$Rscale <- Rscale
      ordi$scaling <- scaling
    }
    specscores <- specscores * multi    
    ordi$cproj <- specscores
    return(ordi)
  }

bean.pcoa <- add.spec.scores.class(bean.pcoa,JellyREL,method = "pcoa.scores")
text(bean.pcoa$cproj[ ,1], bean.pcoa$cproj[, 2],
     labels = row.names(bean.pcoa$cproj), col = "black")

spe.corr <- add.spec.scores.class(bean.pcoa, JellyREL, method = "cor.scores")$cproj
corrcut <- 0.7
imp.spp <- spe.corr[abs(spe.corr[, 1]) >= corrcut | abs(spe.corr[, 2]) >= corrcut, ]

fit <- envfit(bean.pcoa, JellyREL, perm = 999)

print(fit)

# Incidence-Based 

bean.dj <- vegdist(Jellybean_SbyS, method = "jaccard", binary = TRUE)

beaninc.pcoa <- cmdscale(bean.dj, eig = TRUE, k = 3)

Explainvar1inc <- round(beaninc.pcoa$eig[1] / sum(beaninc.pcoa$eig), 3) * 100
Explainvar2inc <- round(beaninc.pcoa$eig[2] / sum(beaninc.pcoa$eig), 3) * 100
Explainvar3inc <- round(beaninc.pcoa$eig[3] / sum(beaninc.pcoa$eig), 3) * 100
Suminc.eig <- sum(Explainvar1inc, Explainvar2inc, Explainvar3inc)

head(row.names(beaninc.pcoa$points))

rownames(beaninc.pcoa$points) <- 1:nrow(beaninc.pcoa$points)

par(mar = c(5,5,1,2) + 0.1)

plot(beaninc.pcoa$points[,1], beaninc.pcoa$points[,2], 
     xlab = paste("PCoA 1 (", Explainvar1inc, "%)", sep = ""),
     ylab = paste("PCoA 2 (", Explainvar2inc, "%)", sep = ""),
     pch = 16, cex = 2.0, type = "n", cex.lab = 1.5,
     cex.axis = 1.2, axes = FALSE,
     xlim = range(beaninc.pcoa$points[,1]) * 1.1,  
     ylim = range(beaninc.pcoa$points[,2]) * 1.1)  


axis(side = 1, labels = T, lwd.ticks = 2, cex.axis = 1.2, las = 1)
axis(side = 2, labels = T, lwd.ticks = 2, cex.axis = 1.2, las = 1)
abline(h = 0, v = 0, lty = 3)
box(lwd = 2)

points(beaninc.pcoa$points[ ,1], beaninc.pcoa$points[ ,2],
       pch = 19, cex = 2.5, bg = "gray", col = "gray")
text(beaninc.pcoa$points[ ,1], beaninc.pcoa$points[ ,2], 
     labels = row.names(beaninc.pcoa$points), cex = 1.0, pos = NULL)

```

> ***Answer 2***:
> Based on the results of the permutation test, the species (flavors in this case) that are contributing to the patterns in the ordination are: sunkist orange, sour cherry, red apple, raspberry, licorice, french vanilla, crushed pineapple, cinnamon, chocolate pudding, caramel corn, and cantaloupe. All of these flavors have statistically signifcant p values and are therefore identified as influential species. Whether you are using an incidence based or abundance based metric, it is important to take that into condsideration with how you interpret your graphs. An incidence based metric is determining if something is present or absent. In this example, it would just give you an understanding of what flavors were present or not, but not how many were present. From an ecological stand point, incidence based metrics focus on species richness. On the other hand, abundance based metrics look at how much of an individual is present. In this example, it is looking at what flavors are present the most and/or least. In an ecological viewpoint, it would be like looking at species evenness. 


**Question 3** Using the preference-profile matrix, determine the most popular jelly bean in the class using a control structure (e.g., for loop, if statement, function, etc).

```{r}
Jellybean_Pref <- read_csv("/cloud/project/QB2025_Brown/Week5-Confection/Jelly belly data! - Preference.csv")

library(tidyverse)

fav_counts <- Jellybean_Pref %>%
  select(-Name) %>% 
  summarise(across(everything(), sum)) %>%
  pivot_longer(cols = everything(), names_to = "Flavor", values_to = "TotalVotes") %>% 
  arrange(desc(TotalVotes))  

most_popular <- fav_counts %>%
  slice_max(TotalVotes, n = 1)

print(most_popular)

```

> ***Answer 3***: 
> Berry Blue was the most popular jellybean flavor with a total of 7 votes.


**Question 4**
In the code chunk below, identify the student in QB who has a preference-profile that is most like yours. 
Quantitatively, how similar are you to your "jelly buddy"?
Visualize the preference profiles of the class by creating a cluster dendogram.
Label each terminal node (a.k.a., tip or "leaf") with the student's name or initials.
Make some observations about the preference-profiles of the class. 


```{r}

#Finding "jelly buddy"

Jellybean_Pref[is.na(Jellybean_Pref)] <- 0

Jellybean_Pref_numeric <- Jellybean_Pref[, -1]

pref.dj <- vegdist(Jellybean_Pref_numeric, method = "jaccard", binary = TRUE)

jaccard_similarity_matrix <- 1- as.matrix(pref.dj)

my_index <- 3 
jelly_buddy <- jaccard_similarity_matrix[my_index, ]

jelly_buddy[my_index] <- NA 

most_similar_person <- which.max(jelly_buddy)

print(most_similar_person)

jaccard_value <- jaccard_similarity_matrix[my_index, most_similar_person]

print(jaccard_value)

"Cluster dendogram"

rownames(Jellybean_Pref_numeric) <- Jellybean_Pref$Name

beanpref.db <- vegdist(Jellybean_Pref_numeric, method = "bray", upper = TRUE, diag = TRUE)

pref.ward <- hclust(beanpref.db, method = "ward.D2")

par(mar = c(1, 5, 2, 2) + 0.1)
plot(pref.ward, main = "Jelly Bean Preferences",
     ylab = "Squared Bray-Curtis Distance", labels = rownames(Jellybean_Pref_numeric), cex = 0.8)

```

> ***Answer 4***:
> Student 7 has the most similiar preference profile as myself. Looking back at the data set, person 7 corresponds to Jaeyoung. We also have a Jaccard similiarity score of ~0.57. This means that Jaeyoung and I share approximately 57% of unique preferences. There are many students who have similiar preferences. For example, Jaeyoung and myself compared to Anna and Ashish have very similiar dissimilarity values; which are very low and means we have similiar preferences. However, given how spread apart our two groups are, our two groups chose very dfferent flavors. Our two groups are also the most similiar when using the Bray-Curtis model compared to other class preferences. The next set of pairs have Bray-Curtis values around 0.6. This value corresponds to not having very similiar preferences. Going back to Jaeyoung and myself, the pair of people who have the most different preferences than us are Trang and Yongsoo because they merged from us very early on and are very far from us on the dendogram.   

## SUBMITTING YOUR ASSIGNMENT
Use Knitr to create a PDF of your completed `7.DiversitySynthesis_Worksheet.Rmd` document, push it to GitHub, and create a pull request.
Please make sure your updated repo includes both the pdf and RMarkdown files.

Unless otherwise noted, this assignment is due on **Wednesday, February 19^th^, 2025 at 12:00 PM (noon)**.